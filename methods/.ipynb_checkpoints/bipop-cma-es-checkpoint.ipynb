{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from cmaes import CMA\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.spatial.distance import pdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def errorfcn(alpha, Xbar, n, m):\n",
    "    f1 = np.reshape(alpha[(2 * n):], (m, 2))\n",
    "    f2 = np.reshape(alpha[0:2 * n], (2, n))\n",
    "    f3 = Xbar[:, 0:n].T\n",
    "    r = (Xbar - np.dot(f1, np.dot(f2, f3)).T) ** 2\n",
    "    return np.nanmean(np.nanmean(r, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../datasets/sklearn-datasets'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-ce7da83567e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msynthetic_datasets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../datasets/sklearn-datasets'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mreal_datasets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../datasets/real-datasets'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../datasets/sklearn-datasets'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "synthetic_datasets = os.listdir('../datasets/sklearn-datasets')\n",
    "real_datasets = os.listdir('../datasets/real-datasets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_dictionary = dict()\n",
    "for f in synthetic_datasets:\n",
    "    try:\n",
    "        df = pd.read_csv(f'../datasets/sklearn-datasets/{f}')\n",
    "        target_columns = [col for col in df.columns if col.startswith('target')]\n",
    "        datasets_dictionary[f] = (df, target_columns)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "for f in real_datasets:\n",
    "    try:\n",
    "        df = pd.read_csv(f'../datasets/real-datasets/{f}').drop(columns = ['instances'])\n",
    "        target_columns = [col for col in df.columns if col.startswith('algo')]\n",
    "        datasets_dictionary[f] = (df, target_columns)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class OptimizationOutput:\n",
    "    A: np.ndarray\n",
    "    B: np.ndarray\n",
    "    C: np.ndarray\n",
    "    Z: np.ndarray\n",
    "    error: float\n",
    "    execution_time: float\n",
    "    n_tries: int\n",
    "    search_space: float\n",
    "    method_name: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def bipop_cma_es(X, Y, **kwargs):\n",
    "    np.random.seed(0)\n",
    "    \n",
    "    Xbar = np.hstack((X, Y))\n",
    "    n = X.shape[1]\n",
    "    m = Xbar.shape[1]\n",
    "\n",
    "    if 'search_space' not in kwargs:\n",
    "        search_space = 32.768\n",
    "    else:\n",
    "        search_space = kwargs['search_space']\n",
    "        \n",
    "    bounds = list()\n",
    "    bounds.append([[-search_space, search_space] for i in range(2 * m + 2 * n)])\n",
    "    bounds = np.array(bounds).reshape((2 * m + 2 * n, 2))\n",
    "\n",
    "    lower_bounds, upper_bounds = bounds[:, 0], bounds[:, 1]\n",
    "    mean = lower_bounds + (np.random.rand(2 * m + 2 * n) * (upper_bounds - lower_bounds))\n",
    "    sigma = search_space * 2 / 5  # 1/5 of the domain width\n",
    "\n",
    "    optimizer = CMA(mean=mean, sigma=sigma, bounds=bounds, seed=0)\n",
    "    \n",
    "    if 'ntries' not in kwargs:\n",
    "        ntries = 100\n",
    "    else:\n",
    "        ntries = kwargs['ntries']\n",
    "\n",
    "    perf = np.zeros(ntries)\n",
    "    alpha = np.zeros((2 * m + 2 * n, ntries))\n",
    "    Hd = pdist(X)[np.newaxis].T\n",
    "\n",
    "    n_restarts = 30  # A small restart doesn't count in the n_restarts\n",
    "    small_n_eval, large_n_eval = 0, 0\n",
    "    popsize0 = optimizer.population_size\n",
    "    inc_popsize = 2\n",
    "\n",
    "    # Initial run is with \"normal\" population size; it is\n",
    "    # the large population before first doubling, but its\n",
    "    # budget accounting is the same as in case of small\n",
    "    # population.\n",
    "    poptype = \"small\"\n",
    "    \n",
    "    start_time = time.time()\n",
    "    for generation in range(ntries):\n",
    "        solutions = []\n",
    "        for _ in range(optimizer.population_size):\n",
    "            alpha[:, generation] = optimizer.ask()\n",
    "\n",
    "            # Calculate function value\n",
    "            value = errorfcn(alpha = alpha[:, generation], Xbar = Xbar, n = n, m = m)\n",
    "            solutions.append((alpha[:, generation], value))\n",
    "    #         print(f\"#{generation} {value} (x1={x[0]}, x2 = {x[1]})\")\n",
    "        optimizer.tell(solutions)\n",
    "\n",
    "        aux = alpha[:, [generation]]\n",
    "        A = np.reshape(aux[0:2 * n], (2, n))\n",
    "        Z = np.dot(X, A.T)\n",
    "        perf[generation] = np.corrcoef(Hd, pdist(Z)[np.newaxis].T, rowvar=False)[0][1]\n",
    "\n",
    "        if optimizer.should_stop():\n",
    "            n_eval = optimizer.population_size * optimizer.generation\n",
    "            if poptype == \"small\":\n",
    "                small_n_eval += n_eval\n",
    "            else:  # poptype == \"large\"\n",
    "                large_n_eval += n_eval\n",
    "\n",
    "            if small_n_eval < large_n_eval:\n",
    "                poptype = \"small\"\n",
    "                popsize_multiplier = inc_popsize ** n_restarts\n",
    "                popsize = math.floor(\n",
    "                    popsize0 * popsize_multiplier ** (np.random.uniform() ** 2)\n",
    "                )\n",
    "            else:\n",
    "                poptype = \"large\"\n",
    "                n_restarts += 1\n",
    "                popsize = popsize0 * (inc_popsize ** n_restarts)\n",
    "\n",
    "            mean = lower_bounds + (np.random.rand(2) * (upper_bounds - lower_bounds))\n",
    "            optimizer = CMA(\n",
    "                mean=mean,\n",
    "                sigma=sigma,\n",
    "                bounds=bounds,\n",
    "                population_size=popsize,\n",
    "            )\n",
    "            print(\"Restart CMA-ES with popsize={} ({})\".format(popsize, poptype))\n",
    "    end_time = time.time()\n",
    "    \n",
    "    idx = np.argmax(perf)\n",
    "    A = np.reshape(alpha[0:2 * n, idx], (2, n))\n",
    "    Z = np.dot(X, A.T)\n",
    "    B = np.reshape(alpha[(2 * n):, idx], (m, 2))\n",
    "    Xhat = np.dot(Z, B.T)\n",
    "    C = B[n:m + 1, :].T\n",
    "    B = B[0:n + 1, :]\n",
    "    error = np.sum((Xbar - Xhat) ** 2)\n",
    "    execution_time = end_time - start_time\n",
    "    \n",
    "    out = OptimizationOutput(A, B, C, Z, error, execution_time, ntries, search_space, 'bipop')\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from experimentation import run_optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_teste = pd.read_csv('../datasets/real-datasets/XOR_metadata.csv').drop(columns = ['instances'])\n",
    "performance_columns = [col for col in df.columns if col.startswith('algo')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "bipop_output = run_optimization(df_teste, performance_columns, bipop_cma_es, ntries = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scatter_plot(x, y, title = None, x_label = None, y_label = None, hue_data = None):\n",
    "    fig, ax = plt.subplots(figsize = (10, 8))\n",
    "    n_colors = len(hue_data.unique())\n",
    "    sns.scatterplot(x = x, y = y, hue = hue_data, palette = sns.color_palette(\"vlag\", n_colors), legend = False)\n",
    "    ax.set_title(title)\n",
    "    sns.despine()\n",
    "    \n",
    "plot_scatter_plot(x = bipop_output.Z[:, 0], \n",
    "                  y = bipop_output.Z[:, 1], \n",
    "                  title = \"Projection\",\n",
    "                  hue_data = df_teste.iloc[:,1],\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "n_tries = 30\n",
    "search_space = 0.1\n",
    "experiments = dict()\n",
    "for filename, item in datasets_dictionary.items():\n",
    "    experiments[filename] = run_optimization(df = item[0], \n",
    "                                             target_columns = item[1], \n",
    "                                             optimization_method = bipop_cma_es, \n",
    "                                             ntries = n_tries,\n",
    "                                             search_space = search_space\n",
    "                                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset_filename in experiments.keys():\n",
    "    plot_scatter_plot(x = experiments[dataset_filename].Z[:, 0],\n",
    "                     y = experiments[dataset_filename].Z[:, 1],\n",
    "                      hue_data = datasets_dictionary[dataset_filename][0].iloc[:, 0],\n",
    "                     title = dataset_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from experimentation import create_results_dataframe\n",
    "\n",
    "bipop_results_df = create_results_dataframe(experiments)\n",
    "bipop_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bipop_results_df.to_excel(f'results/bipop-results-ntries{n_tries}-searchspace{search_space}.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
